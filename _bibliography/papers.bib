---
---

# Thesis

phdthesis{phdthesisjx,
  author = {Xu, Junshen},
  title = {A Robust and Efficient Framework for Slice-to-Volume Reconstruction: Application to Fetal MRI},
  school = {Massachusetts Institute of Technology},
  abbr = "Thesis",
  abstract = {Volumetric reconstruction in presence of motion is a challenging problem in medical imaging. When imaging moving targets, many modalities are limited to fast 2D imaging techniques that provide cross-sectional snapshots (2D images) of the subject with an attempt to "freeze" in-plane motion. However, inter-slice movement results in slice misalignment in 3D space, i.e., each image being an independent slice that fails to form a coherent volume for diagnosis and analysis. To this end, slice-to-volume reconstruction (SVR) has been proposed to reconstruct a high-quality 3D volume from misaligned 2D observations by performing inter-slice motion correction and super-resolution reconstruction. Existing SVR algorithms, however, have a limited capture range of slice motion and are time-consuming, particularly when producing high-resolution volumes. This thesis proposes a motion-robust and efficient machine learning framework for SVR, motivated by the application of magnetic resonance imaging (MRI) in assessing fetal brain development. We first introduce a slice-to-volume registration transformer that models input slices as a sequence and performs inter-slice motion correction by simultaneously predicting rigid transformations of all images in 3D space. We then reformulate the reconstruction problem using implicit neural representation, where the underlying volume is represented by a continuous function of 3D coordinates. This resolution-agnostic approach allows efficient reconstruction of high-resolution volumes. Finally, we extend this method to data that suffer from non-rigid motion by introducing an implicit motion field that captures slice-dependent deformation. These advances together enable robust and efficient 3D reconstruction and visualization in fetal MRI, benefiting diagnosis and downstream analysis. Additionally, the proposed framework has the potential for broader clinical implications in various applications that involve similar volumetric reconstruction problems.},
  year = {2023}
}

mastersthesis{masterthesisjx,
  author = {Xu, Junshen},
  title = {Online, Low-Latency Decision Making for Fetal Magnetic Resonance Imaging with Machine Learning},
  school = {Massachusetts Institute of Technology},
  url = {https://dspace.mit.edu/handle/1721.1/127446},
  abbr = "Thesis",
  abstract = {Fetal Magnetic Resonance Imaging (MRI) with T2-weighted Half-Fourier-Acquisition Single-Shot Turbo-Spin-Echo (HASTE) sequence plays an important role in diagnosing brain abnormality. However, the quality of HASTE images routinely suffer from fetal motion which leads to image artifacts, incomplete brain coverage as well as longer scan times. To address this problem, interleaved 3D Echo-planar Imaging (EPI) navigators are acquired along with HASTE images, which can provide pose information for prospective motion correction. In this thesis, we first propose a fetal pose estimation model which detects important fetal landmarks from 3D EPI data using a deep convolution neural network. We further demonstrate its capability by applying this model to fetal motion analysis. In an attempt to improve the current fetal MRI protocol, we develop a machine learning based online decision making system for fetal MRI to improve the efficiency of acquiring high quality HASTE images for clinical diagnosis. The proposed system leverages an Image Quality Assessment (IQA) network to determine whether an acquired HASTE slice is contaminated by motion artifacts and improves image quality by re-acquisition. Evaluation on retrospective experiments and in vivo scans suggests that the proposed pipeline can improve image quality with a reasonable number of re-acquisition, potentially enabling a more efficient workflow for fetal brain MRI.},
  year = {2020}
  }

# SVR

@article{liong2024sfamnet,
author={Liong, Gen-Bing and Liong, Sze-Teng and Chan, Chee Seng and See, John},
journal={Neurocomputing}, 
title="{SFAMNet: A Scene Flow Attention-based Micro-expression Network}", 
year={2024},
volume={566},
number={},
pages={126998},
publisher={Elsevier},
doi={10.1016/j.neucom.2023.126998},
selected={true},
code = "https://github.com/genbing99/SFAMNet",
preview = "sfamnet.png",
abstract = {Tremendous progress has been made in facial Micro-Expression (ME) spotting and recognition; however, most works have focused on either spotting or recognition tasks on the 2D videos. Until recently, the estimation of the 3D motion field (a.k.a scene flow) for the ME has only become possible after the release of the multi-modal ME dataset. In this paper, we propose the first Scene Flow Attention-based Micro-expression Network, namely SFAMNet. It takes the scene flow computed using the RGB-D flow algorithm as the input and predicts the spotting confidence score and emotion labels. Specifically, SFAMNet is an attention-based end-to-end multi-stream multi-task network devised to spot and recognize the ME. Besides that, we present a data augmentation strategy to alleviate the small sample size problem during network learning. Extensive experiments are performed on three tasks: (i) ME spotting; (ii) ME recognition; and (iii) ME analysis on the multi-modal CAS(ME)^3 dataset. Empirical results indicate that depth is vital in capturing the ME information and the effectiveness of the proposed approach. Our source code is publicly available at <a href="https://github.com/genbing99/SFAMNet">https://github.com/genbing99/SFAMNet</a>.},
url = "https://ieeexplore.ieee.org/document/10015091",
abbr = "NeuComp",
pdf = "https://www.techrxiv.org/articles/preprint/NeSVoR_Implicit_Neural_Representation_for_Slice-to-Volume_Reconstruction_in_MRI/21398868"
}

@article{yang2023doing,
author={Yang, Cong and Yang, Zhenyu and Ke, Yan and Chen, Tao and Grzegorzek, Marcin and See, John},
journal={IEEE Transactions on Image Processing},
title={Doing More With Moir{\'e} Pattern Detection in Digital Photos},  
year={2023},
volume={32},
pages={694--708},
publisher={IEEE},
doi={10.1109/TIP.2022.3232232},
selected={true},
code = "https://github.com/cong-yang/MoireDet",
preview = "moiredet.png",
abstract = {Detecting moiré patterns in digital photographs is meaningful as it provides priors towards image quality evaluation and demoiréing tasks. In this paper, we present a simple yet efficient framework to extract moiré edge maps from images with moiré patterns. The framework includes a strategy for training triplet (natural image, moiré layer, and their synthetic mixture) generation, and a Moiré Pattern Detection Neural Network (MoireDet) for moiré edge map estimation. This strategy ensures consistent pixel-level alignments during training, accommodating characteristics of a diverse set of camera-captured screen images and real-world moiré patterns from natural images. The design of three encoders in MoireDet exploits both high-level contextual and low-level structural features of various moiré patterns. Through comprehensive experiments, we demonstrate the advantages of MoireDet: better identification precision of moiré images on two datasets, and a marked improvement over state-of-the-art demoiréing methods.},
url = "https://ieeexplore.ieee.org/document/10006755",
abbr = "TIP",
pdf = "https://researchportal.hw.ac.uk/files/83582564/Doing_More_With_Moir_Pattern_Detection_in_Digital_Photos.pdf",
video = "moiredet-demo.mp4"
}

@article{gohar2023slice,
  author={Gohar, Imad and Halimi, Abderrahim and See, John and Yew, Weng Kean and Yang, Cong},
  journal={Machines},
  title={Slice-Aided Defect Detection in Ultra High-Resolution Wind Turbine Blade Images},
  year={2023},
  volume={11},
  number={10},
  pages={953},
  publisher={MDPI},
  doi={10.3390/machines11100953},
  selected={true},
  code = "https://github.com/imadgohar/DTU-annotations",
  preview = "slice-wtb.png",
  abstract = {The processing of aerial images taken by drones is a challenging task due to their high resolution and the presence of small objects. The scale of the objects varies diversely depending on the position of the drone, which can result in loss of information or increased difficulty in detecting small objects. To address this issue, images are either randomly cropped or divided into small patches before training and inference. This paper proposes a defect detection framework that harnesses the advantages of slice-aided inference for small and medium-size damage on the surface of wind turbine blades. This framework enables the comparison of different slicing strategies, including a conventional patch division strategy and a more recent slice-aided hyper-inference, on several state-of-the-art deep neural network baselines for the detection of surface defects in wind turbine blade images. Our experiments provide extensive empirical results, highlighting the benefits of using the slice-aided strategy and the significant improvements made by these networks on an ultra high-resolution drone image dataset.},
  url = "https://www.mdpi.com/2075-1702/11/10/953",
  abbr = "Machines",
  pdf = "https://www.mdpi.com/2075-1702/11/10/953/pdf?version=1697117170"
}

@article{yang2022fatigueview,
  author={Yang, Cong and Yang, Zhenyu and Li, Weiyu and See, John},
  journal={IEEE Transactions on Intelligent Transportation Systems},
  title={FatigueView: A Multi-Camera Video Dataset for Vision-Based Drowsiness Detection},
  volume={24},
  number={1},
  pages={233--246},
  year={2022},
  publisher={IEEE},
  doi={10.1109/TITS.2022.3216017},
  selected={true},
  website = "https://fatigueview.github.io",
  code = "https://github.com/FatigueView/fatigueview",
  preview = "fatigueview.png",
  abstract = {Although vision-based drowsiness detection approaches have achieved great success on empirically organized datasets, it remains far from being satisfactory for deployment in practice. One crucial issue lies in the scarcity and lack of datasets that represent the actual challenges in real-world applications, e.g. tremendous variation and aggregation of visual signs, challenges brought on by different camera positions and camera types. To promote research in this field, we introduce a new large-scale dataset, FatigueView, that is collected by both RGB and infrared (IR) cameras from five different positions. It contains real sleepy driving videos and various visual signs of drowsiness from subtle to obvious, e.g. with 17,403 different yawning sets totaling more than 124 million frames, far more than recent actively used datasets. We also provide hierarchical annotations for each video, ranging from spatial face landmarks and visual signs to temporal drowsiness locations and levels to meet different research requirements. We structurally evaluate representative methods to build viable baselines. With FatigueView, we would like to encourage the community to adapt computer vision models to address practical real-world concerns, particularly the challenges posed by this dataset.},
  url = "https://ieeexplore.ieee.org/abstract/document/9931532",
  abbr = "TITS",
  pdf = "https://pure.hw.ac.uk/ws/files/67344144/FatigueView_A_Multi_Camera_Video_Dataset_for_Vision_Based_Drowsiness_Detection.pdf"
}

InProceedings{10.1007/978-3-031-16446-0_1,
author="Xu, Junshen
and Moyer, Daniel
and Grant, P. Ellen
and Golland, Polina
and Iglesias, Juan Eugenio
and Adalsteinsson, Elfar",
editor="Wang, Linwei
and Dou, Qi
and Fletcher, P. Thomas
and Speidel, Stefanie
and Li, Shuo",
title="SVoRT: Iterative Transformer for Slice-to-Volume Registration in Fetal Brain MRI",
booktitle="Medical Image Computing and Computer Assisted Intervention -- MICCAI 2022",
year="2022",
publisher="Springer Nature Switzerland",
address="Cham",
pages="3--13",
abstract="Volumetric reconstruction of fetal brains from multiple stacks of MR slices, acquired in the presence of almost unpredictable and often severe subject motion, is a challenging task that is highly sensitive to the initialization of slice-to-volume transformations. We propose a novel slice-to-volume registration method using Transformers trained on synthetically transformed data, which model multiple stacks of MR slices as a sequence. With the attention mechanism, our model automatically detects the relevance between slices and predicts the transformation of one slice using information from other slices. We also estimate the underlying 3D volume to assist slice-to-volume registration and update the volume and transformations alternately to improve accuracy. Results on synthetic data show that our method achieves lower registration error and better reconstruction quality compared with existing state-of-the-art methods. Experiments with real-world MRI data are also performed to demonstrate the ability of the proposed model to improve the quality of 3D reconstruction under severe fetal motion.",
isbn="978-3-031-16446-0",
abbr="MICCAI",
preview="svort.png",
arXiv="2206.10802",
code = "https://github.com/daviddmc/SVoRT",
url = "https://doi.org/10.1007/978-3-031-16446-0_1",
poster = "svort_poster.pdf"
}

article{https://doi.org/10.1002/mrm.29106,
author = {Gagoski*, Borjan and Xu*, Junshen and Wighton, Paul and Tisdall, M. Dylan and Frost, Robert and Lo, Wei-Ching and Golland, Polina and van der Kouwe, Andre and Adalsteinsson, Elfar and Grant, P. Ellen},
title = {Automated Detection and Reacquisition of Motion-Degraded Images in Fetal HASTE Imaging at 3 T},
journal = {Magnetic Resonance in Medicine},
volume = {87},
number = {4},
pages = {1914-1922},
keywords = {automated image quality assessment, fetal brain MRI, HASTE MRI with reacquisition},
doi = {https://doi.org/10.1002/mrm.29106},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/mrm.29106},
eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1002/mrm.29106},
abstract = {Purpose: Fetal brain Magnetic Resonance Imaging suffers from unpredictable and unconstrained fetal motion that causes severe image artifacts even with half-Fourier single-shot fast spin echo (HASTE) readouts. This work presents the implementation of a closed-loop pipeline that automatically detects and reacquires HASTE images that were degraded by fetal motion without any human interaction. Methods: A convolutional neural network that performs automatic image quality assessment (IQA) was run on an external GPU-equipped computer that was connected to the internal network of the MRI scanner. The modified HASTE pulse sequence sent each image to the external computer, where the IQA convolutional neural network evaluated it, and then the IQA score was sent back to the sequence. At the end of the HASTE stack, the IQA scores from all the slices were sorted, and only slices with the lowest scores (corresponding to the slices with worst image quality) were reacquired. Results: The closed-loop HASTE acquisition framework was tested on 10 pregnant mothers, for a total of 73 acquisitions of our modified HASTE sequence. The IQA convolutional neural network, which was successfully employed by our modified sequence in real time, achieved an accuracy of 85.2\% and area under the receiver operator characteristic of 0.899. Conclusion: The proposed acquisition/reconstruction pipeline was shown to successfully identify and automatically reacquire only the motion degraded fetal brain HASTE slices in the prescribed stack. This minimizes the overall time spent on HASTE acquisitions by avoiding the need to repeat the entire stack if only few slices in the stack are motion-degraded.},
year = {2022},
abbr = {MRM},
preview = "iqa_loop.png",
}

InProceedings{10.1007/978-3-030-59725-2_37,
author="Xu, Junshen
and Lala, Sayeri
and Gagoski, Borjan
and Abaci Turk, Esra
and Grant, P. Ellen
and Golland, Polina
and Adalsteinsson, Elfar",
editor="Martel, Anne L.
and Abolmaesumi, Purang
and Stoyanov, Danail
and Mateus, Diana
and Zuluaga, Maria A.
and Zhou, S. Kevin
and Racoceanu, Daniel
and Joskowicz, Leo",
title="Semi-Supervised Learning for Fetal Brain MRI Quality Assessment with ROI Consistency",
booktitle="Medical Image Computing and Computer Assisted Intervention -- MICCAI 2020",
year="2020",
publisher="Springer International Publishing",
address="Cham",
pages="386--395",
abstract="Fetal brain MRI is useful for diagnosing brain abnormalities but is challenged by fetal motion. The current protocol for T2-weighted fetal brain MRI is not robust to motion so image volumes are degraded by inter- and intra- slice motion artifacts. Besides, manual annotation for fetal MR image quality assessment are usually time-consuming. Therefore, in this work, a semi-supervised deep learning method that detects slices with artifacts during the brain volume scan is proposed. Our method is based on the mean teacher model, where we not only enforce consistency between student and teacher models on the whole image, but also adopt an ROI consistency loss to guide the network to focus on the brain region. The proposed method is evaluated on a fetal brain MR dataset with 11,223 labeled images and more than 200,000 unlabeled images. Results show that compared with supervised learning, the proposed method can improve model accuracy by about 6{\%} and outperform other state-of-the-art semi-supervised learning methods. The proposed method is also implemented and evaluated on an MR scanner, which demonstrates the feasibility of online image quality assessment and image reacquisition during fetal MR scans.",
isbn="978-3-030-59725-2",
abbr="MICCAI",
arXiv="2006.12704",
url="https://doi.org/10.1007/978-3-030-59725-2_37",
poster = "iqa_poster.pdf",
preview = "iqa_network.png",
code="https://github.com/daviddmc/fetal-IQA"
}

# fetal pose

InProceedings{10.1007/978-3-030-32251-9_44,
author="Xu*, Junshen
and Zhang*, Molin
and Turk, Esra Abaci
and Zhang, Larry
and Grant, P. Ellen
and Ying, Kui
and Golland, Polina
and Adalsteinsson, Elfar",
editor="Shen, Dinggang
and Liu, Tianming
and Peters, Terry M.
and Staib, Lawrence H.
and Essert, Caroline
and Zhou, Sean
and Yap, Pew-Thian
and Khan, Ali",
title="Fetal Pose Estimation in Volumetric MRI using a 3D Convolution Neural Network",
booktitle="Medical Image Computing and Computer Assisted Intervention -- MICCAI 2019",
year="2019",
publisher="Springer International Publishing",
address="Cham",
pages="403--410",
abstract="The performance and diagnostic utility of magnetic resonance imaging (MRI) in pregnancy is fundamentally constrained by fetal motion. Motion of the fetus, which is unpredictable and rapid on the scale of conventional imaging times, limits the set of viable acquisition techniques to single-shot imaging with severe compromises in signal-to-noise ratio and diagnostic contrast, and frequently results in unacceptable image quality. Surprisingly little is known about the characteristics of fetal motion during MRI and here we propose and demonstrate methods that exploit a growing repository of MRI observations of the gravid abdomen that are acquired at low spatial resolution but relatively high temporal resolution and over long durations (10--30 min). We estimate fetal pose per frame in MRI volumes of the pregnant abdomen via deep learning algorithms that detect key fetal landmarks. Evaluation of the proposed method shows that our framework achieves quantitatively an average error of 4.47 mm and 96.4{\%} accuracy (with error less than 10 mm). Fetal pose estimation in MRI time series yields novel means of quantifying fetal movements in health and disease, and enables the learning of kinematic models that may enhance prospective mitigation of fetal motion artifacts during MRI acquisition.",
isbn="978-3-030-32251-9",
abbr="MICCAI",
preview="fetal_pose.png",
arXiv="1907.04500",
code="https://github.com/daviddmc/fetal-pose",
url="https://doi.org/10.1007/978-3-030-32251-9_44",
poster = "fetal_pose_poster.pdf",
selected={true},
}

InProceedings{10.1007/978-3-030-59725-2_38,
author="Zhang*, Molin
and Xu*, Junshen
and Abaci Turk, Esra
and Grant, P. Ellen
and Golland, Polina
and Adalsteinsson, Elfar",
editor="Martel, Anne L.
and Abolmaesumi, Purang
and Stoyanov, Danail
and Mateus, Diana
and Zuluaga, Maria A.
and Zhou, S. Kevin
and Racoceanu, Daniel
and Joskowicz, Leo",
title="Enhanced Detection of Fetal Pose in 3D MRI by Deep Reinforcement Learning with Physical Structure Priors on Anatomy",
booktitle="Medical Image Computing and Computer Assisted Intervention -- MICCAI 2020",
year="2020",
publisher="Springer International Publishing",
address="Cham",
pages="396--405",
abstract="Fetal MRI is heavily constrained by unpredictable and substantial fetal motion that causes image artifacts and limits the set of viable diagnostic image contrasts. Current mitigation of motion artifacts is predominantly performed by fast, single-shot MRI and retrospective motion correction. Estimation of fetal pose in real time during MRI stands to benefit prospective methods to detect and mitigate fetal motion artifacts where inferred fetal motion is combined with online slice prescription with low-latency decision making. Current developments of deep reinforcement learning (DRL), offer a novel approach for fetal landmarks detection. In this task 15 agents are deployed to detect 15 landmarks simultaneously by DRL. The optimization is challenging, and here we propose an improved DRL that incorporates priors on physical structure of the fetal body. First, we use graph communication layers to improve the communication among agents based on a graph where each node represents a fetal-body landmark. Further, additional reward based on the distance between agents and physical structures such as the fetal limbs is used to fully exploit physical structure. Evaluation of this method on a repository of 3-mm resolution in vivo data demonstrates a mean accuracy of landmark estimation 10 mm of ground truth as 87.3{\%}, and a mean error of 6.9 mm. The proposed DRL for fetal pose landmark search demonstrates a potential clinical utility for online detection of fetal motion that guides real-time mitigation of motion artifacts as well as health diagnosis during MRI of the pregnant mother.",
isbn="978-3-030-59725-2",
abbr="MICCAI",
url="https://doi.org/10.1007/978-3-030-59725-2_38"
}

article{doi:10.1148/radiol.2018180940,
author = {Chen, Kevin T. and Gong, Enhao and de Carvalho Macruz, Fabiola Bezerra and Xu, Junshen and Boumis, Athanasia and Khalighi, Mehdi and Poston, Kathleen L. and Sha, Sharon J. and Greicius, Michael D. and Mormino, Elizabeth and Pauly, John M. and Srinivas, Shyam and Zaharchuk, Greg},
title = {Ultra-Low-Dose 18F-Florbetaben Amyloid PET Imaging Using Deep Learning with Multi-Contrast MRI Inputs},
journal = {Radiology},
volume = {290},
number = {3},
pages = {649-656},
year = {2019},
doi = {10.1148/radiol.2018180940},
note = {PMID: 30526350},
URL = {https://doi.org/10.1148/radiol.2018180940},
eprint = {https://doi.org/10.1148/radiol.2018180940},
abbr="Radiology",
abstract = { PurposeTo reduce radiotracer requirements for amyloid PET/MRI without sacrificing diagnostic quality by using deep learning methods.Materials and MethodsForty data sets from 39 patients (mean age ± standard deviation [SD], 67 years ± 8), including 16 male patients and 23 female patients (mean age, 66 years ± 6 and 68 years ± 9, respectively), who underwent simultaneous amyloid (fluorine 18 [18F]–florbetaben) PET/MRI examinations were acquired from March 2016 through October 2017 and retrospectively analyzed. One hundredth of the raw list-mode PET data were randomly chosen to simulate a low-dose (1\%) acquisition. Convolutional neural networks were implemented with low-dose PET and multiple MR images (PET-plus-MR model) or with low-dose PET alone (PET-only) as inputs to predict full-dose PET images. Quality of the synthesized images was evaluated while Bland-Altman plots assessed the agreement of regional standard uptake value ratios (SUVRs) between image types. Two readers scored image quality on a five-point scale (5 = excellent) and determined amyloid status (positive or negative). Statistical analyses were carried out to assess the difference of image quality metrics and reader agreement and to determine confidence intervals (CIs) for reading results.ResultsThe synthesized images (especially from the PET-plus-MR model) showed marked improvement on all quality metrics compared with the low-dose image. All PET-plus-MR images scored 3 or higher, with proportions of images rated greater than 3 similar to those for the full-dose images (−10\% difference [eight of 80 readings], 95\% CI: −15\%, −5\%). Accuracy for amyloid status was high (71 of 80 readings [89\%]) and similar to intrareader reproducibility of full-dose images (73 of 80 [91\%]). The PET-plus-MR model also had the smallest mean and variance for SUVR difference to full-dose images.ConclusionSimultaneously acquired MRI and ultra–low-dose PET data can be used to synthesize full-dose–like amyloid PET images.© RSNA, 2018Online supplemental material is available for this article.See also the editorial by Catana in this issue. }
}

InProceedings{10.1007/978-3-030-87202-1_21,
author="Xu, Junshen
and Chen, Eric Z.
and Chen, Xiao
and Chen, Terrence
and Sun, Shanhui",
editor="de Bruijne, Marleen
and Cattin, Philippe C.
and Cotin, St{\'e}phane
and Padoy, Nicolas
and Speidel, Stefanie
and Zheng, Yefeng
and Essert, Caroline",
title="Multi-Scale Neural ODEs for 3D Medical Image Registration",
booktitle="Medical Image Computing and Computer Assisted Intervention -- MICCAI 2021",
year="2021",
publisher="Springer International Publishing",
address="Cham",
pages="213--223",
abstract="Image registration plays an important role in medical image analysis. Conventional optimization based methods provide an accurate estimation due to the iterative process at the cost of expensive computation. Deep learning methods such as learn-to-map are much faster but either iterative or coarse-to-fine approach is required to improve accuracy for handling large motions. In this work, we proposed to learn a registration optimizer via a multi-scale neural ODE model. The inference consists of iterative gradient updates similar to a conventional gradient descent optimizer but in a much faster way, because the neural ODE learns from the training data to adapt the gradient efficiently at each iteration. Furthermore, we proposed to learn a modal-independent similarity metric to address image appearance variations across different image contrasts. We performed evaluations through extensive experiments in the context of multi-contrast 3D MR images from both public and private data sources and demonstrate the superior performance of our proposed methods.",
isbn="978-3-030-87202-1",
abbr="MICCAI",
preview="ode.png",
arXiv="2106.08493",
url="https://doi.org/10.1007/978-3-030-87202-1_21",
poster = "ode_poster.pdf",
selected={true},
}


# template

string{aps = {American Physical Society,}}

@book{einstein1956investigations,
  bibtex_show={true},
  title={Investigations on the Theory of the Brownian Movement},
  author={Einstein, Albert},
  year={1956},
  publisher={Courier Corporation},
  preview={brownian-motion.gif}
}

@article{einstein1950meaning,
  abbr={AJP},
  bibtex_show={true},
  title={The meaning of relativity},
  author={Einstein, Albert and Taub, AH},
  journal={American Journal of Physics},
  volume={18},
  number={6},
  pages={403--404},
  year={1950},
  publisher={American Association of Physics Teachers}
}

@article{PhysRev.47.777,
  abbr={PhysRev},
  title={Can Quantum-Mechanical Description of Physical Reality Be Considered Complete?},
  author={Einstein, A. and Podolsky, B. and Rosen, N.},
  abstract={In a complete theory there is an element corresponding to each element of reality. A sufficient condition for the reality of a physical quantity is the possibility of predicting it with certainty, without disturbing the system. In quantum mechanics in the case of two physical quantities described by non-commuting operators, the knowledge of one precludes the knowledge of the other. Then either (1) the description of reality given by the wave function in quantum mechanics is not complete or (2) these two quantities cannot have simultaneous reality. Consideration of the problem of making predictions concerning a system on the basis of measurements made on another system that had previously interacted with it leads to the result that if (1) is false then (2) is also false. One is thus led to conclude that the description of reality as given by a wave function is not complete.},
  journal={Phys. Rev.},
  volume={47},
  issue={10},
  pages={777--780},
  numpages={0},
  year={1935},
  month={May},
  publisher=aps,
  doi={10.1103/PhysRev.47.777},
  url={http://link.aps.org/doi/10.1103/PhysRev.47.777},
  html={https://journals.aps.org/pr/abstract/10.1103/PhysRev.47.777},
  pdf={example_pdf.pdf},
  altmetric={248277},
  dimensions={true},
  selected={false}
}

@article{einstein1905molekularkinetischen,
  title={{\"U}ber die von der molekularkinetischen Theorie der W{\"a}rme geforderte Bewegung von in ruhenden Fl{\"u}ssigkeiten suspendierten Teilchen},
  author={Einstein, A.},
  journal={Annalen der physik},
  volume={322},
  number={8},
  pages={549--560},
  year={1905},
  publisher={Wiley Online Library}
}

@article{einstein1905movement,
  abbr={Ann. Phys.},
  title={Un the movement of small particles suspended in statiunary liquids required by the molecular-kinetic theory 0f heat},
  author={Einstein, A.},
  journal={Ann. Phys.},
  volume={17},
  pages={549--560},
  year={1905}
}

@article{einstein1905electrodynamics,
  title={On the electrodynamics of moving bodies},
  author={Einstein, A.},
  year={1905}
}

@book{przibram1967letters,
  bibtex_show={true},
  title={Letters on wave mechanics},
  author={Einstein, Albert and Schrödinger, Erwin and Planck, Max and Lorentz, Hendrik Antoon and Przibram, Karl},
  year={1967},
  publisher={Vision},
  preview={wave-mechanics.gif}
}
